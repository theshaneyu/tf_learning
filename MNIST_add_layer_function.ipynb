{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "y_true = tf.placeholder(tf.float32, [None, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__把加layer寫成一個function__\n",
    "\n",
    "這編寫的add_layer其實只是幫我做了把input資料，乘上一個W矩陣加上bias，也就是一層fully connected層的意思，最後activation function再經過一個softmax，最後輸出就是網路的輸出，已經可以和ground truth label算cross entropy\n",
    "\n",
    "__NOTE: __裡面的 __W__ 和 __bias__ 宣告的方式會影響其初始化的方式，往往對訓練品質會有很大的影響，需要作好的調整"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_layer(inputs, in_size, out_size, activation_function=None):\n",
    "    \"\"\"\n",
    "    args1 input: 輸入input的placeholder\n",
    "    args2 in_size: input維度\n",
    "    args3 out_size: output維度\n",
    "    args4 activation_function: 激勵函數，通常是tf.nn下的函式\n",
    "    \"\"\"\n",
    "    W = tf.Variable(tf.zeros([in_size, out_size]))\n",
    "    bias = tf.Variable(tf.zeros([out_size]) + 0.1)\n",
    "    WX_plus_b = tf.matmul(inputs, W) + bias\n",
    "    if activation_function is None:\n",
    "        outputs = WX_plus_b\n",
    "    else:\n",
    "        outputs = activation_function(WX_plus_b)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__ML第一步-定義模型__\n",
    "\n",
    "這邊使用寫好的add_layer函式，使用softmax函式，輸入維度維784，輸出維度為10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hidden_layer_1_output = add_layer(X, 784, 100, activation_function=tf.nn.relu)\n",
    "# output = add_layer(hidden_layer_1_output, 100, 10, activation_function=tf.nn.softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = add_layer(X, 784, 10, activation_function=tf.nn.softmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ML第二步-定義Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_true * tf.log(output), reduction_indices=[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ML第三步-Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "寫一個evaluation function方便之後計算accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return accuracy\n",
    "def evaluation(feed_dict):\n",
    "    correct_prediction = tf.equal(tf.argmax(output, 1), tf.argmax(y_true, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    return sess.run(accuracy, feed_dict = feed_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "開始執行computational graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第 0 輪訓練的Loss為 2.30259 Accuracy為 0.26\n",
      "第 50 輪訓練的Loss為 0.654547 Accuracy為 0.88\n",
      "第 100 輪訓練的Loss為 0.375277 Accuracy為 0.91\n",
      "第 150 輪訓練的Loss為 0.23663 Accuracy為 0.97\n",
      "第 200 輪訓練的Loss為 0.399992 Accuracy為 0.94\n",
      "第 250 輪訓練的Loss為 0.419386 Accuracy為 0.9\n",
      "第 300 輪訓練的Loss為 0.419795 Accuracy為 0.92\n",
      "第 350 輪訓練的Loss為 0.288841 Accuracy為 0.95\n",
      "第 400 輪訓練的Loss為 0.255768 Accuracy為 0.95\n",
      "第 450 輪訓練的Loss為 0.236842 Accuracy為 0.95\n",
      "第 500 輪訓練的Loss為 0.309623 Accuracy為 0.9\n",
      "第 550 輪訓練的Loss為 0.202164 Accuracy為 0.95\n",
      "第 600 輪訓練的Loss為 0.42038 Accuracy為 0.89\n",
      "第 650 輪訓練的Loss為 0.266696 Accuracy為 0.94\n",
      "第 700 輪訓練的Loss為 0.469481 Accuracy為 0.92\n",
      "第 750 輪訓練的Loss為 0.342953 Accuracy為 0.93\n",
      "第 800 輪訓練的Loss為 0.430723 Accuracy為 0.9\n",
      "第 850 輪訓練的Loss為 0.279548 Accuracy為 0.95\n",
      "第 900 輪訓練的Loss為 0.279916 Accuracy為 0.95\n",
      "第 950 輪訓練的Loss為 0.293623 Accuracy為 0.95\n",
      "第 1000 輪訓練的Loss為 0.329601 Accuracy為 0.91\n",
      "第 1050 輪訓練的Loss為 0.301589 Accuracy為 0.95\n",
      "第 1100 輪訓練的Loss為 0.241949 Accuracy為 0.94\n",
      "第 1150 輪訓練的Loss為 0.459778 Accuracy為 0.89\n",
      "第 1200 輪訓練的Loss為 0.291139 Accuracy為 0.93\n",
      "第 1250 輪訓練的Loss為 0.303607 Accuracy為 0.94\n",
      "第 1300 輪訓練的Loss為 0.374343 Accuracy為 0.94\n",
      "第 1350 輪訓練的Loss為 0.357862 Accuracy為 0.93\n",
      "第 1400 輪訓練的Loss為 0.317282 Accuracy為 0.95\n",
      "第 1450 輪訓練的Loss為 0.277152 Accuracy為 0.94\n",
      "第 1500 輪訓練的Loss為 0.27498 Accuracy為 0.91\n",
      "第 1550 輪訓練的Loss為 0.365529 Accuracy為 0.92\n",
      "第 1600 輪訓練的Loss為 0.344107 Accuracy為 0.91\n",
      "第 1650 輪訓練的Loss為 0.342359 Accuracy為 0.92\n",
      "第 1700 輪訓練的Loss為 0.222424 Accuracy為 0.92\n",
      "第 1750 輪訓練的Loss為 0.357721 Accuracy為 0.93\n",
      "第 1800 輪訓練的Loss為 0.371627 Accuracy為 0.94\n",
      "第 1850 輪訓練的Loss為 0.32768 Accuracy為 0.94\n",
      "第 1900 輪訓練的Loss為 0.168829 Accuracy為 0.95\n",
      "第 1950 輪訓練的Loss為 0.31903 Accuracy為 0.93\n",
      "訓練花費 4.079588174819946 秒\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "\n",
    "start = time()\n",
    "\n",
    "for i in range(2000):\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "#     sess.run(train_step, feed_dict={X: batch_xs, y_true: batch_ys})\n",
    "    \"\"\"\n",
    "    如果執行sess.run的時候，也一起執行cross_entropy這個node\n",
    "    則sess.run可以回傳「當次iteration的loss」，如以下程式碼\n",
    "    \"\"\"\n",
    "    _, current_loss = sess.run([train_step, cross_entropy], feed_dict={X: batch_xs, y_true: batch_ys})\n",
    "\n",
    "    if i % 50 == 0:\n",
    "        print('第', i, '輪訓練的Loss為', current_loss, 'Accuracy為', evaluation({X: batch_xs, y_true: batch_ys}))\n",
    "        \n",
    "end = time()\n",
    "print('訓練花費', (end-start), '秒')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Data Accuracy:  0.9212\n",
      "Training Data Accuracy:  0.919873\n"
     ]
    }
   ],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(output, 1), tf.argmax(y_true, 1)) # 注意這邊的 y 和 y_ 都是placeholder\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print('Testing Data Accuracy: ', evaluation({X: mnist.test.images, y_true: mnist.test.labels}))\n",
    "print('Training Data Accuracy: ', evaluation({X: mnist.train.images, y_true: mnist.train.labels}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_tf_learning",
   "language": "python",
   "name": "venv_tf_learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
