{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "y_true = tf.placeholder(tf.float32, [None, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__把加layer寫成一個function__\n",
    "\n",
    "這編寫的add_layer其實只是幫我做了把input資料，乘上一個W矩陣加上bias，也就是一層fully connected層的意思，最後activation function再經過一個softmax，最後輸出就是網路的輸出，已經可以和ground truth label算cross entropy\n",
    "\n",
    "__NOTE: __裡面的 __W__ 和 __bias__ 宣告的方式會影響其初始化的方式，往往對訓練品質會有很大的影響，需要作好的調整"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_layer(inputs, in_size, out_size, activation_function=None):\n",
    "    \"\"\"\n",
    "    args1 input: 輸入input的placeholder\n",
    "    args2 in_size: input維度\n",
    "    args3 out_size: output維度\n",
    "    args4 activation_function: 激勵函數，通常是tf.nn下的函式\n",
    "    \"\"\"\n",
    "    W = tf.Variable(tf.zeros([in_size, out_size]))\n",
    "    bias = tf.Variable(tf.zeros([out_size]) + 0.1)\n",
    "    WX_plus_b = tf.matmul(inputs, W) + bias\n",
    "    if activation_function is None:\n",
    "        outputs = WX_plus_b\n",
    "    else:\n",
    "        outputs = activation_function(WX_plus_b)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__ML第一步-定義模型__\n",
    "\n",
    "這邊使用寫好的add_layer函式，使用softmax函式，輸入維度維784，輸出維度為10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hidden_layer_1_output = add_layer(X, 784, 100, activation_function=tf.nn.relu)\n",
    "# output = add_layer(hidden_layer_1_output, 100, 10, activation_function=tf.nn.softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = add_layer(X, 784, 10, activation_function=tf.nn.softmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ML第二步-定義Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_true * tf.log(output), reduction_indices=[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ML第三步-Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "開始執行computational graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第 0 輪訓練的Loss為 0.184176\n",
      "第 50 輪訓練的Loss為 0.284074\n",
      "第 100 輪訓練的Loss為 0.268324\n",
      "第 150 輪訓練的Loss為 0.212792\n",
      "第 200 輪訓練的Loss為 0.327426\n",
      "第 250 輪訓練的Loss為 0.334656\n",
      "第 300 輪訓練的Loss為 0.182557\n",
      "第 350 輪訓練的Loss為 0.179001\n",
      "第 400 輪訓練的Loss為 0.39459\n",
      "第 450 輪訓練的Loss為 0.205549\n",
      "第 500 輪訓練的Loss為 0.31461\n",
      "第 550 輪訓練的Loss為 0.3483\n",
      "第 600 輪訓練的Loss為 0.23946\n",
      "第 650 輪訓練的Loss為 0.288157\n",
      "第 700 輪訓練的Loss為 0.259424\n",
      "第 750 輪訓練的Loss為 0.229819\n",
      "第 800 輪訓練的Loss為 0.182715\n",
      "第 850 輪訓練的Loss為 0.27714\n",
      "第 900 輪訓練的Loss為 0.231333\n",
      "第 950 輪訓練的Loss為 0.340513\n",
      "第 1000 輪訓練的Loss為 0.181208\n",
      "第 1050 輪訓練的Loss為 0.346117\n",
      "第 1100 輪訓練的Loss為 0.364409\n",
      "第 1150 輪訓練的Loss為 0.349409\n",
      "第 1200 輪訓練的Loss為 0.210036\n",
      "第 1250 輪訓練的Loss為 0.264438\n",
      "第 1300 輪訓練的Loss為 0.52017\n",
      "第 1350 輪訓練的Loss為 0.287668\n",
      "第 1400 輪訓練的Loss為 0.251905\n",
      "第 1450 輪訓練的Loss為 0.409638\n",
      "第 1500 輪訓練的Loss為 0.243659\n",
      "第 1550 輪訓練的Loss為 0.293755\n",
      "第 1600 輪訓練的Loss為 0.31353\n",
      "第 1650 輪訓練的Loss為 0.365671\n",
      "第 1700 輪訓練的Loss為 0.192871\n",
      "第 1750 輪訓練的Loss為 0.106423\n",
      "第 1800 輪訓練的Loss為 0.219986\n",
      "第 1850 輪訓練的Loss為 0.284489\n",
      "第 1900 輪訓練的Loss為 0.265077\n",
      "第 1950 輪訓練的Loss為 0.352936\n",
      "訓練花費 3.3853816986083984 秒\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "\n",
    "start = time()\n",
    "\n",
    "for i in range(2000):\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "#     sess.run(train_step, feed_dict={X: batch_xs, y_true: batch_ys})\n",
    "    \"\"\"\n",
    "    如果執行sess.run的時候，也一起執行cross_entropy這個node\n",
    "    則sess.run可以回傳「當次iteration的loss」，如以下程式碼\n",
    "    \"\"\"\n",
    "    _, current_loss = sess.run([train_step, cross_entropy], feed_dict={X: batch_xs, y_true: batch_ys})\n",
    "\n",
    "    if i % 50 == 0:\n",
    "        print('第', i, '輪訓練的Loss為', current_loss)\n",
    "        \n",
    "end = time()\n",
    "print('訓練花費', (end-start), '秒')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Data Accuracy:  0.9199\n",
      "Training Data Accuracy:  0.924455\n"
     ]
    }
   ],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(output, 1), tf.argmax(y_true, 1)) # 注意這邊的 y 和 y_ 都是placeholder\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print('Testing Data Accuracy: ', sess.run(accuracy, feed_dict = {X: mnist.test.images, y_true: mnist.test.labels}))\n",
    "print('Training Data Accuracy: ', sess.run(accuracy, feed_dict = {X: mnist.train.images, y_true: mnist.train.labels}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_tf_learning",
   "language": "python",
   "name": "venv_tf_learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
